features:
  ollama:
    enabled: false
  langfuse:
    enabled: true
  qdrant:
    enabled: true
  frontend:
    enabled: true


backend:
  name: backend
  replicaCount: 1

  image:
    repository: schwarzit-xx-sit-rag-template-sit-stackit-docker-local.jfrog.io
    name: rag-backend
    pullPolicy: Always
    tag: "dev-ba20c7b"

  command:
  - "poetry"
  - "run"
  args:
  - "python"
  - "-m"
  - "uvicorn"
  - "main:perfect_rag_app"
  - "--host"
  - "0.0.0.0"
  - "--port"
  - "8080"
  - "--loop"
  - "asyncio"

  workers: 3
  wsMaxQueue: 6

  debugArgs:
  - "python"
  - "-m"
  - "debugpy"
  - "--wait-for-client"
  - "--listen"
  - "0.0.0.0:31415"
  - "-m"
  - "uvicorn"
  - "main:perfect_rag_app"
  - "--host"
  - "0.0.0.0"
  - "--port"
  - "8080"
  - "--reload"
  - "--reload-dir"
  - "/app/rag-backend"
  - "--reload-dir"
  - "/app/rag-core-library/rag-core-api"
  - "--reload-dir"
  - "/app/rag-core-library/rag-core-lib"
  - "--loop"
  - "asyncio"

  service:
    type: ClusterIP
    port: 8080

  pythonPathEnv:
    PYTHONPATH: src

  ingress:
    enabled: true
    host:
      name: rag.localhost
      path: /api/chat(/|$)(.*)
      pathType: ImplementationSpecific
      port: 8080

  secrets:
    alephAlpha:
      apiKey: "sk-123456"
    basicAuth: ""
    langfuse:
      publicKey: "pk-lf"
      secretKey: "sk-lf"
    stackitMyapiLlm:
      authClientId: auth-client-id
      authClientSecret: auth-client-secret
    stackitEmbedder:
      apiKey: ""
    openai:
      apiKey: "sk-123456"
    stackitVllm:
      apiKey: "sk-123"
    usecase:

  envs:
    stackitVllm:
      STACKIT_VLLM_MODEL: neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8
      STACKIT_VLLM_BASE_URL: https://api.openai-compat.model-serving.eu01.onstackit.cloud/v1
    database:
      VECTOR_DB_COLLECTION_NAME: rag-db
      VECTOR_DB_URL: http://rag-qdrant:6333
    retriever:
      RETRIEVER_THRESHOLD: 0.3
      RETRIEVER_K_DOCUMENTS: 10
      RETRIEVER_TOTAL_K: 7
      RETRIEVER_SUMMARY_THRESHOLD: 0.3
      RETRIEVER_SUMMARY_K_DOCUMENTS: 10
      RETRIEVER_TABLE_THRESHOLD: 0.3
      RETRIEVER_TABLE_K_DOCUMENTS: 10
      RETRIEVER_IMAGE_THRESHOLD: 0.7
      RETRIEVER_IMAGE_K_DOCUMENTS: 10
    stackitMyapiLlm:
      STACKIT_TOKEN_LIFETIME_MARGIN: 30
      STACKIT_AUTH_SERVER_URL: https://dev.api.schwarz/oauth/accesstoken/v2
    alephAlpha:
      ALEPH_ALPHA_MODEL: llama-3-70b-instruct
      ALEPH_ALPHA_HOST: https://dev.api.schwarz/sit/uapc-public/luminous-api/v1
      ALEPH_ALPHA_TOP_K: 0
      ALEPH_ALPHA_TOP_P: 0
      ALEPH_ALPHA_PRESENCE_PENALTY: 0
      ALEPH_ALPHA_FREQUENCY_PENALTY: 0
      ALEPH_ALPHA_MAXIMUM_TOKENS: 256
      ALEPH_ALPHA_TEMPERATURE: 0
      ALEPH_ALPHA_N: 1
      ALEPH_ALPHA_BEST_OF: 2
    errorMessages:
      ERROR_MESSAGES_NO_DOCUMENTS_MESSAGE: "I'm sorry, my responses are limited. You must ask the right questions."
      ERROR_MESSAGES_NO_OR_EMPTY_COLLECTION: "No documents were provided for searching."
      ERROR_MESSAGES_HARMFUL_QUESTION: "I'm sorry, but harmful requests cannot be processed."
      ERROR_MESSAGES_NO_ANSWER_FOUND: "I'm sorry, I couldn't find an answer with the context provided."
    langfuse:
      LANGFUSE_DATASET_NAME: "rag_test_ds"
      LANGFUSE_DATASET_FILENAME: "/app/test_data.json"
      LANGFUSE_HOST: "http://rag-langfuse:3000" #NOTE: http protocol needs to be defined!
    ragClassTypes:
      RAG_CLASS_TYPE_LLM_TYPE: "stackit"
    ragas:
      RAGAS_IS_DEBUG: false
      RAGAS_MODEL: "gpt-3.5-turbo-0125"
      RAGAS_TIMEOUT: 60
      RAGAS_ADAPT_PROMPTS_TO_LANG: false
      RAGAS_PROMPT_LANGUAGE: "german"
      RAGAS_BASE_URL: "https://api.openai.com/v1"
      RAGAS_EVALUATION_DATASET_NAME: "eval-data"
      RAGAS_MAX_CONCURRENCY: "5"
    embedderClassTypes:
      EMBEDDER_CLASS_TYPE_EMBEDDER_TYPE: "stackit"
    stackitEmbedder:
      STACKIT_EMBEDDER_MODEL: "intfloat/e5-mistral-7b-instruct"
      STACKIT_EMBEDDER_BASE_URL: https://api.openai-compat.model-serving.eu01.onstackit.cloud/v1
    public:
      PUBLIC_HOST: "https://api.aleph-alpha.com"
    ollama:
      OLLAMA_MODEL: "llama3:instruct"
      OLLAMA_BASE_URL: "http://rag-ollama:11434"
      OLLAMA_TOP_K: 0
      OLLAMA_TOP_P: 0
      OLLAMA_TEMPERATURE: 0
    reranker:
      RERANKER_K_DOCUMENTS: 5
      RERANKER_MIN_RELEVANCE_SCORE: 0.001
    usecase:
      USECASE_KEYVALUE_PORT: 6379
      USECASE_KEYVALUE_HOST: "rag-keydb"
    chatHistory:
      CHAT_HISTORY_LIMIT: 4
      CHAT_HISTORY_REVERSE: true

frontend:
  name: frontend
  replicaCount: 1
  image:
    # TODO: Change to jfrog/azure or something else
    repository: schwarzit-xx-sit-rag-template-sit-stackit-docker-local.jfrog.io
    name: frontend
    pullPolicy: Always
    tag: "dev-e12f8cc"

  service:
    type: ClusterIP
    port: 8080

  config:
    envs:
      VITE_API_URL: http://rag.localhost/api
      VITE_CHAT_URL: http://rag.localhost

  ingress:
    enabled: true
    host:
      name: rag.localhost
      path: /
      pathType: ImplementationSpecific
      port: 8080

  secrets:
    viteAuth:
      VITE_AUTH_USERNAME: ""
      VITE_AUTH_PASSWORD: ""

  envs:
    vite:
      VITE_CHAT_AUTH_ENABLED: true
      VITE_API_URL: "http://rag.localhost/api"
      VITE_CHAT_URL: "http://rag.localhost"
      VITE_ADMIN_URL: "http://admin.rag.localhost"
      VITE_ADMIN_API_URL: "http://admin.rag.localhost/api"



adminBackend:
  replicaCount: 1

  name: admin-backend

  image:
    repository: schwarzit-xx-sit-rag-template-sit-stackit-docker-local.jfrog.io
    name: admin-backend
    pullPolicy: Always
    tag: "443892"

  command:
  - "poetry"
  - "run"
  args:
  - "python"
  - "-m"
  - "uvicorn"
  - "main:perfect_admin_app"
  - "--host"
  - "0.0.0.0"
  - "--port"
  - "8080"
  - "--root-path"
  - "/api"
  debugArgs:
  - "python"
  - "-m"
  - "debugpy"
  - "--wait-for-client"
  - "--listen"
  - "0.0.0.0:31415"
  - "-m"
  - "uvicorn"
  - "main:perfect_admin_app"
  - "--host"
  - "0.0.0.0"
  - "--port"
  - "8080"
  - "--reload"
  - "--reload-dir"
  - "/app/admin-backend"
  - "--reload-dir"
  - "/app/rag-core-library/rag-core-lib"
  - "--reload-dir"
  - "/app/rag-core-library/admin-api-lib"
  - "--root-path"
  - "/api"

  service:
    type: ClusterIP
    port: 8080

  pythonPathEnv:
    PYTHONPATH: src

  ingress:
    enabled: true
    host:
      name: admin.rag.localhost
      path: /api(/|$)(.*)
      pathType: ImplementationSpecific
      port: 8080

  minio:
    enabled: true

  envs:
    summarizer:
      SUMMARIZER_MAXIMUM_INPUT_SIZE: "8000"
      SUMMARIZER_MAXIMUM_CONCURRENCY: "10"
    ragapi:
      RAG_API_HOST: "http://backend:8080"
    chunker:
      CHUNKER_MAX_SIZE: 1000
      CHUNKER_OVERLAP: 300


extractor:
  replicaCount: 1
  name: extractor
  image:
    repository: schwarzit-xx-sit-rag-template-sit-stackit-docker-local.jfrog.io
    name: document-extractor
    pullPolicy: Always
    tag: "443892"

  command:
  - "poetry"
  - "run"
  args:
  - "python"
  - "-m"
  - "uvicorn"
  - "main:perfect_extractor_app"
  - "--host"
  - "0.0.0.0"
  - "--port"
  - "8080"
  debugArgs:
  - "python"
  - "-m"
  - "debugpy"
  - "--wait-for-client"
  - "--listen"
  - "0.0.0.0:31415"
  - "-m"
  - "uvicorn"
  - "main:perfect_extractor_app"
  - "--host"
  - "0.0.0.0"
  - "--port"
  - "8080"
  - "--reload"
  - "--reload-dir"
  - "/app/document-extractor"
  - "--reload-dir"
  - "/app/rag-core-library/extractor-api-lib"


  service:
    type: ClusterIP
    port: 8080

  pythonPathEnv:
    PYTHONPATH: src

adminFrontend:
  name: admin-frontend
  replicaCount: 1
  image:
    repository: schwarzit-xx-sit-rag-template-sit-stackit-docker-local.jfrog.io
    name: admin-frontend
    pullPolicy: Always
    tag: "443892"

  service:
    type: ClusterIP
    port: 8080

  exports:
    chart_name:
      adminFrontendChartName: admin-frontend

  ingress:
    enabled: true
    host:
      name: admin.rag.localhost
      path: /
      pathType: ImplementationSpecific
      port: 8080

shared:
# These values are used accross all templates
  ssl: true

  debug:
    backend:
      enabled: false

  imagePullSecret:
    create: false
    name: cr-credentials

  config:
    dns:
    - rag.localhost
    - admin.rag.localhost
    basicAuth:
      enabled: true
    tls:
      enabled: true
      host: rag.localhost
      secretName: tls-certificate

  secrets:
    s3:
      accessKey: "admin"
      secretKey: "password"

  envs:
    pdfExtractor:
      PDF_EXTRACTOR_DIAGRAMS_FOLDER_NAME: "connection_diagrams"
      PDF_EXTRACTOR_FOOTER_HEIGHT: 155
    s3:
      S3_ENDPOINT: http://rag-minio:9000
      S3_BUCKET: documents
